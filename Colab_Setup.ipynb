{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_title"
   },
   "source": [
    "# Healthcare AI Multi-Task Projects - Colab Setup\n",
    "\n",
    "This notebook sets up the environment and installs all necessary dependencies for the Healthcare AI Multi-Task Projects.\n",
    "\n",
    "## Projects Included:\n",
    "1. **Task 1**: ECG Arrhythmia Classification Using CNN\n",
    "2. **Task 2**: Fine-tune Bio_ClinicalBERT for Clinical Note Classification\n",
    "3. **Task 3**: LLaMA 3.1 Text Summarization\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpu_setup"
   },
   "source": [
    "## 1. Enable GPU Runtime (Recommended)\n",
    "\n",
    "For faster training, enable GPU runtime:\n",
    "1. Go to **Runtime** ‚Üí **Change runtime type**\n",
    "2. Set **Hardware accelerator** to **GPU**\n",
    "3. Click **Save**\n",
    "\n",
    "**Note**: GPU runtime is recommended but not required. CPU training will work but be slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_gpu"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "\n",
    "print(\"üñ•Ô∏è  GPU Status Check\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ CUDA available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"   GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    print(f\"   PyTorch version: {torch.__version__}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  CUDA not available - training will be slower\")\n",
    "    print(f\"   PyTorch version: {torch.__version__}\")\n",
    "    print(\"   Consider enabling GPU runtime for faster training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_dependencies"
   },
   "source": [
    "## 2. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_packages"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q transformers datasets accelerate evaluate\n",
    "!pip install -q rouge-score sacrebleu\n",
    "!pip install -q scikit-learn matplotlib seaborn plotly\n",
    "!pip install -q nltk gdown kaggle\n",
    "!pip install -q tqdm ipywidgets\n",
    "\n",
    "print(\"‚úÖ All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_nltk"
   },
   "outputs": [],
   "source": [
    "# Download NLTK data\n",
    "import nltk\n",
    "\n",
    "print(\"üìö Downloading NLTK data...\")\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "print(\"‚úÖ NLTK data downloaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "verify_installation"
   },
   "source": [
    "## 3. Verify Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "verify_imports"
   },
   "outputs": [],
   "source": [
    "# Test key imports\n",
    "print(\"üîç Testing key imports...\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "imports_to_test = [\n",
    "    ('numpy', 'NumPy'),\n",
    "    ('pandas', 'Pandas'),\n",
    "    ('torch', 'PyTorch'),\n",
    "    ('transformers', 'Transformers'),\n",
    "    ('sklearn', 'Scikit-learn'),\n",
    "    ('matplotlib', 'Matplotlib'),\n",
    "    ('seaborn', 'Seaborn'),\n",
    "    ('plotly', 'Plotly'),\n",
    "    ('nltk', 'NLTK'),\n",
    "    ('datasets', 'Datasets'),\n",
    "    ('evaluate', 'Evaluate'),\n",
    "    ('rouge_score', 'ROUGE Score'),\n",
    "    ('sacrebleu', 'SacreBLEU')\n",
    "]\n",
    "\n",
    "all_imports_ok = True\n",
    "for module, name in imports_to_test:\n",
    "    try:\n",
    "        __import__(module)\n",
    "        print(f\"‚úÖ {name}\")\n",
    "    except ImportError as e:\n",
    "        print(f\"‚ùå {name}: {e}\")\n",
    "        all_imports_ok = False\n",
    "\n",
    "if all_imports_ok:\n",
    "    print(\"\\nüéâ All imports successful! Environment is ready.\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Some imports failed. Please check the error messages above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_gpu_training"
   },
   "outputs": [],
   "source": [
    "# Test GPU training capability\n",
    "print(\"üß™ Testing GPU training capability...\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "# Create a simple test model\n",
    "class TestModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(100, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "model = TestModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Test on CPU\n",
    "print(\"Testing CPU training...\")\n",
    "x_cpu = torch.randn(32, 100)\n",
    "y_cpu = torch.randint(0, 10, (32,))\n",
    "\n",
    "start_time = time.time()\n",
    "for _ in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(x_cpu)\n",
    "    loss = criterion(output, y_cpu)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "cpu_time = time.time() - start_time\n",
    "print(f\"CPU training time: {cpu_time:.3f} seconds\")\n",
    "\n",
    "# Test on GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"\\nTesting GPU training...\")\n",
    "    model_gpu = TestModel().cuda()\n",
    "    optimizer_gpu = torch.optim.Adam(model_gpu.parameters())\n",
    "    \n",
    "    x_gpu = torch.randn(32, 100).cuda()\n",
    "    y_gpu = torch.randint(0, 10, (32,)).cuda()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for _ in range(10):\n",
    "        optimizer_gpu.zero_grad()\n",
    "        output = model_gpu(x_gpu)\n",
    "        loss = criterion(output, y_gpu)\n",
    "        loss.backward()\n",
    "        optimizer_gpu.step()\n",
    "    gpu_time = time.time() - start_time\n",
    "    print(f\"GPU training time: {gpu_time:.3f} seconds\")\n",
    "    print(f\"Speedup: {cpu_time/gpu_time:.2f}x\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  GPU not available - skipping GPU test\")\n",
    "\n",
    "print(\"\\n‚úÖ Training capability test completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "next_steps"
   },
   "source": [
    "## 4. Next Steps\n",
    "\n",
    "Now that the environment is set up, you can run the three main project notebooks:\n",
    "\n",
    "### üìä Task 1: ECG Arrhythmia Classification\n",
    "- **File**: `Task1_ECG_CNN.ipynb`\n",
    "- **Description**: Classify arrhythmias from ECG signals using CNN\n",
    "- **Key Features**: 1D CNN, class imbalance handling, comprehensive evaluation\n",
    "\n",
    "### üè• Task 2: Bio_ClinicalBERT Fine-tuning\n",
    "- **File**: `Task2_BioClinicalBERT.ipynb`\n",
    "- **Description**: Fine-tune Bio_ClinicalBERT for clinical note classification\n",
    "- **Key Features**: 22 medical categories, Hugging Face Transformers, class weights\n",
    "\n",
    "### üìù Task 3: LLaMA 3.1 Text Summarization\n",
    "- **File**: `Task3_LLaMA_Summarization.ipynb`\n",
    "- **Description**: Fine-tune LLaMA 3.1 for abstractive summarization\n",
    "- **Key Features**: CNN/DailyMail dataset, ROUGE/BLEU evaluation, sequence-to-sequence\n",
    "\n",
    "### üöÄ Getting Started\n",
    "1. **Open any of the three notebooks**\n",
    "2. **Run all cells sequentially** (Cell ‚Üí Run All)\n",
    "3. **Follow the markdown instructions** in each notebook\n",
    "4. **Monitor training progress** and adjust parameters if needed\n",
    "\n",
    "### üí° Tips for Success\n",
    "- **Enable GPU runtime** for faster training\n",
    "- **Run cells in order** - don't skip ahead\n",
    "- **Monitor memory usage** - restart runtime if needed\n",
    "- **Save your work** - download notebooks and results\n",
    "- **Check the README.md** for detailed information\n",
    "\n",
    "### üîß Troubleshooting\n",
    "- **Out of memory**: Restart runtime and reduce batch size\n",
    "- **Import errors**: Re-run the setup cells\n",
    "- **Slow training**: Enable GPU runtime\n",
    "- **Dataset issues**: Check the dataset_links.md file\n",
    "\n",
    "---\n",
    "\n",
    "**Ready to start? Open one of the task notebooks and begin your Healthcare AI journey! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}